# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
default_experiment: all
default_data_file: 'benchmarks.data'

runs:
    invocations: 1
    iterations: 100
    min_iteration_time: 100
    
.iteration_numbers:
    fast_vm_macro:      &FAST_VM_MACRO      1500
    slow_vm_macro:      &SLOW_VM_MACRO      800
    fast_vm_micro:      &FAST_VM_MICRO      800
    slow_vm_micro:      &SLOW_VM_MICRO      400


# definition of benchmark suites
benchmark_suites:
    are-we-fast-java:
        gauge_adapter: RebenchLog
        location: Benchmarks/AreWeFast/benchmarks/Java
        command: " -cp benchmarks.jar Harness %(benchmark)s %(variable)s "
        iterations: *FAST_VM_MACRO ## the number iterations measured
        max_invocation_time: 6000
        benchmarks: &AWF
            - DeltaBlue:
                extra_args: 12000
            - Richards:
                extra_args: 100
            - Json:
                extra_args: 100
            - CD:
                extra_args: 100
            - Havlak:
                extra_args: 1500
            
            - Bounce:
                extra_args: 1500
            - List:
                extra_args: 1500
            - Mandelbrot:
                extra_args: 500
            - NBody:
                extra_args: 250000
            - Permute:
                extra_args: 1000
            - Queens:
                extra_args: 1000
            - Sieve:
                extra_args: 3000
            - Storage:
                extra_args: 1000
            - Towers:
                extra_args: 600    

    are-we-fast-r:
        gauge_adapter: RebenchLog
        location: Benchmarks/AreWeFast/benchmarks/R
        command: " Harness.r %(benchmark)s %(iterations)s "
        iterations: 10 ## the number iterations measured
        max_invocation_time: 6000
        benchmarks: 
            - Mandelbrot:
                extra_args: 500

    are-we-fast-js:
        gauge_adapter: RebenchLog
        location: Benchmarks/AreWeFast/benchmarks/JavaScript
        command: "harness.js %(benchmark)s %(variable)s "
        iterations: *FAST_VM_MACRO ## the number iterations measured
        max_invocation_time: 6000
        benchmarks: *AWF

    are-we-fast-st:
        gauge_adapter: RebenchLog
        location: Benchmarks/AreWeFast/benchmarks/Smalltalk
        command: "AWFY_Pharo.image run.st %(benchmark)s %(variable)s "
        iterations: *FAST_VM_MACRO ## the number iterations measured
        max_invocation_time: 6000
        benchmarks: *AWF
             
# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    RIR:
        path: "Implementations/R/RIR/tools"
        binary: R
        args: "-headless"
    Java:
        path: &IMPLEMENTATIONS_PATH Implementations
        binary: java8.sh
#        args: "-Xms2048m -server "
    Node:
        path: *IMPLEMENTATIONS_PATH
        binary: node.sh
    Pharo:
      path: "Implementations/pharo"
      binary: pharo
                
# define the benchmarks to be executed for a re-executable benchmark run
experiments:
    AreWeFast:
        data_file: areWeFast.data
        executions:
          - RIR:
              suites:
                - are-we-fast-r
          - Java:
              suites:
                - are-we-fast-java
          - Node:
              suites:
                - are-we-fast-js
          - Pharo:
              suites:
                - are-we-fast-st